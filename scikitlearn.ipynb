{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scikitlearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rapid130RS/iris_dataset/blob/master/scikitlearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4M_-lXugldIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "42dd9fcd-679a-44ab-f2fc-9504dd42daf7"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python  \n",
        "#this is to demonstrate the use of Scikit learn in analysing a data set and creating a proof of concept for basic predicitive analytics\n",
        "#see <https://scikit-learn.org/stable/tutorial/basic/tutorial.html>\n",
        "\n",
        "import numpy as np\n",
        "import sklearn                                                                  #import scikit learn\n",
        "import pandas as pd                                                             # allows input/output of a CSV file and processing\n",
        "#iris = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv') \n",
        "                                                                                # I imported the data set from a URL due to the IDE that I use, but the data also comes with scikit.\n",
        "from sklearn.datasets import load_iris                                          # Sklearn has the Iris dataset preloaded. Equally, I could use the dataset that I imported to this repo.\n",
        "iris = load_iris()\n",
        "# print (iris)                                                                  # print output to see how the data is imported. I commented this out as I only wanted to read the data and the structure of the array.\n",
        "n_samples, n_features = iris.data.shape                                         # the data the s_samples and n_features refer to the two dimensional array. Numpy recognises the columns and rows in the array as features and samples respectively. \n",
        "                                                                                # the iris data attribute is a numpy array\n",
        "numberOfSamples = str(n_samples)\n",
        "numberOfFeatures = str(n_features)\n",
        "firstRecord = str(iris.data[0])                                                 # iris.data; data is an attribute already defined in the dataset\n",
        "nameOfClasses = str(iris.target_names[0])                                       # in the scikit iris dataset, target names is assigned in the array.\n",
        "print (\"Overview of the dataset:\\n\")\n",
        "print (\"The number of samples studied is: \"+ numberOfSamples)                   # there are 150 samples\n",
        "print (\"The number of features (Petal and Sepel) is: \"+ numberOfFeatures)       # there are 4 columns\n",
        "print (\"The data for the first record is :\"+ firstRecord)                       # this is the first sample in the dataset, the sepal length is 5.1cm, width 3.5cm, Petal length is 1.4cm and width 0.2cm\n",
        "print (\"The first record refers to Sepal length as \"+str(iris.data[0,0])+\".cm, Seple width is \"+str(iris.data[0,1])+\".cm, Petal length is \"+str(iris.data[0,2])+\".cm and Petal width is \"+str(iris.data[0,3])+ \".cm \")\n",
        "print (\"The three classes of flowers are :\"+ str(iris.target_names[0])+\", \"+str(iris.target_names[1])+\" and \"+str(iris.target_names[2])+\".\\n\")\n",
        "                                                                                # this outputs the values in the array.\n",
        "                                                                                # Having had a brief look at the date set, I want to look at what SchKit can do in predictive analysis\n",
        "X, y = iris.data, iris.target                                                   # I define two variables. X is in caps as the data var is two dimensional, while y is lower case as is one dimensional\n",
        "from sklearn.svm import LinearSVC                                               # import linear support vector classification machine- a machine learning class that is used to conduct machine learning\n",
        "clf = LinearSVC(C=150,max_iter=1000000)                                          # create the classifier (clf) and assign the value c=150, which is the total number of samples. The max number of iterations is quite high.\n",
        "clf = clf.fit(X,y)                                                              # this is the fit function, which is an initial step in creating an machine learning environment. A convergence warning may appear here, depending on the version of python. It can be ignored.\n",
        "#print (\"The process of training the model revises the array: \"+ str(clf.coef_))# I left these two lines as I twill want to print the output of the fit function in the future\n",
        "#print (clf.intercept_) \n",
        "                                                                                # Having defined the model, it can be used to predict values\n",
        "newSepelLength=float(input(\"Enter the length of the Sepel: \"))                  # Next few lines are to gather user input - converting the string to float.\n",
        "newSepelWidth=float(input(\"Enter the width of the Sepel: \"))\n",
        "newPetelLength=float(input(\"Enter the length of the Petel: \"))\n",
        "newPetelWidth=float(input(\"Enter the width of the Petel: \"))\n",
        "newMeasurement=np.array([newSepelLength, newSepelWidth, newPetelLength, newPetelWidth])\n",
        "                                                                                # this is an array of user input\n",
        "arrayForTest=newMeasurement.reshape(-1,4)                                       # I needed to resize the array as I kept getting errors; a 2 dem array was expected.\n",
        "print (\"You entered: \"+str(arrayForTest))\n",
        "clf.predict(arrayForTest)\n",
        "#print (clf.predict(arrayForTest))                                              # the output of the predict function is a figure, indicating the class of Iris\n",
        "print(\"The genus (class) of Iris you have is identifed as \"+str(iris.target_names[clf.predict(arrayForTest)])+\".\")\n",
        "                                                                                # this outputs the class of flower, there is not any exception catching feature as this is a proof of concept\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overview of the dataset:\n",
            "\n",
            "The number of samples studied is: 150\n",
            "The number of features (Petal and Sepel) is: 4\n",
            "The data for the first record is :[5.1 3.5 1.4 0.2]\n",
            "The first record refers to Sepal length as 5.1.cm, Seple width is 3.5.cm, Petal length is 1.4.cm and Petal width is 0.2.cm \n",
            "The three classes of flowers are :setosa, versicolor and virginica.\n",
            "\n",
            "Enter the length of the Sepel: 4\n",
            "Enter the width of the Sepel: 1\n",
            "Enter the length of the Petel: 6\n",
            "Enter the width of the Petel: 8\n",
            "You entered: [[4. 1. 6. 8.]]\n",
            "[2]\n",
            "The genus (class) of Iris you have is identifed as ['virginica'].\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}