{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scikitlearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rapid130RS/iris_dataset/blob/master/scikitlearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4M_-lXugldIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "2b4e07f8-c0b6-4591-e262-8c4424ec2d73"
      },
      "cell_type": "code",
      "source": [
        "#this is to deomonstrate the use of Scikit learn in analysing a data set\n",
        "#see <https://scikit-learn.org/stable/tutorial/basic/tutorial.html>\n",
        "\n",
        "import numpy as np\n",
        "import sklearn #import scikit learn\n",
        "import pandas as pd # allows input/output of a CSV file and processing\n",
        "#iris = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv') # I imported the data set from a URL due to the IDE that I use. \n",
        "from sklearn.datasets import load_iris  #Sklearn has the Iris dataset preloaded                                                                                               # Equally, I could use the dataset that I imported to this repo.\n",
        "iris = load_iris()\n",
        "# print (iris) #print output to see how the data is imported. I commneted this out as I only wanted to read the data and the structure of the array.\n",
        "n_samples, n_features = iris.data.shape #the data the s_samples and n_features refer to the two demensional array. Numpy recognises the columns and rows in the array as features and samples respectively. \n",
        "# the iris data attribute is a numpy array\n",
        "numberOfSamples = str(n_samples)\n",
        "numberOfFeatures = str(n_features)\n",
        "firstRecord = str(iris.data[0]) #iris.data; data is an attribute already defined in the dataset\n",
        "nameOfClasses = str(iris.target_names[0]) #in the scikit iris dataset, target names is assigned in the array.\n",
        "print (\"Overview of the dataset:\")\n",
        "print (\"The number of samples studied is: \"+ numberOfSamples) # there are 150 samples\n",
        "print (\"The number of features (Petal and Sepel) is: \"+ numberOfFeatures) # there are 4 colums\n",
        "print (\"The data for the first record is :\"+ firstRecord)# this is the first sample in the dataset, the seple lenght is 5.1cm, width 3.5cm, Petal length is 1.4cm and width 0.2cm\n",
        "print (\"The first record refers to Sepel length as \"+str(iris.data[0,0])+\".cm, Seple width is \"+str(iris.data[0,1])+\".cm, Petel length is \"+str(iris.data[0,2])+\".cm and Petal width is \"+str(iris.data[0,3])+ \".cm \")\n",
        "print (\"The three classes of flower studes are :\"+ str(iris.target_names[0])+\", \"+str(iris.target_names[1])+\" and \"+str(iris.target_names[2])+\".\")# this outputs the values in the array for the \n",
        "# Having had a brief look at the date set, I want to look at what SchKit can do\n",
        "X, y = iris.data, iris.target #define two variables. X is in caps as the data var is two dememensial, while y is lower case as is one demensiaonla\n",
        "from sklearn.svm import LinearSVC #import linear support vector classifacaiton machine- a machine learning class that is used to conduct machine learning\n",
        "#LinearSVC() #looking at the class and its attributes, commented out once reviewed\n",
        "clf= LinearSVC(C=150) #create the classifer (clf) and asign the value c=150, which is the total number of samples. C need not be the number of samples.\n",
        "clf = clf.fit(X,y) #this is the fit function, which is an intital step in creeating an machine learning environment. A convergence warning may appear here, depending on the version of python. It can be ignored.\n",
        "print (\"The process of trainng the model revises the array: \"+ str(clf.coef_))\n",
        "#print (clf.intercept_) \n",
        "# Having defined the model, it can be used to predict values\n",
        "newSepelLength=input(\"Enter the length of the Sepel: \")\n",
        "newSepelWidth=input(\"Enter the width of the Sepel: \")\n",
        "newPetelLength=input(\"Enter the length of the Petel: \")\n",
        "newPetelWidth=input(\"Enter the width of the Petel: \")\n",
        "dt = np.dtype(float)\n",
        "newMeasurement=np.array([newSepelLength, newSepelWidth, newPetelLength, newPetelWidth],dtype=dt)[0]\n",
        "#array=newMeasurement\n",
        "clf.predict(newMeasurement)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Overview of the dataset:\n",
            "The number of samples studied is: 150\n",
            "The number of features (Petal and Sepel) is: 4\n",
            "The data for the first record is :[5.1 3.5 1.4 0.2]\n",
            "The first record refers to Sepel length as 5.1.cm, Seple width is 3.5.cm, Petel length is 1.4.cm and Petal width is 0.2.cm \n",
            "The three classes of flower studes are :setosa, versicolor and virginica.\n",
            "The process of trainng the model revises the array: [[ 0.30772161  0.43036528 -1.04233045 -0.6167985 ]\n",
            " [-0.14102201 -1.07258     0.61939029 -1.24248939]\n",
            " [-0.84575845 -1.27615417  1.80231037  3.10533105]]\n",
            "Enter the length of the Sepel: 5\n",
            "Enter the width of the Sepel: 3.6\n",
            "Enter the length of the Petel: 1.3\n",
            "Enter the width of the Petel: .25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-e5f6abb863c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnewMeasurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewSepelLength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewSepelWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewPetelLength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewPetelWidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#array=newMeasurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewMeasurement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    543\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=5.0.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ]
}